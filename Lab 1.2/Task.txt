Have a look at the file 'exercise01.py' and try to understand it. It has the same structure as the previous matlab exercise, but adapted to python. The script illustrates the use of the scikit-learn python module and, in particular, of confusion_matrix and roc_curve for a two-class classifier. You are strongly encouraged to review the corresponding documentation (you can also use help(command) to get more details).

On a successful anaconda installation, you can open the file with spyder and run it pressing F5. It should work both with python 2 and 3.

Once you run it, you have the results obtained from a 2-class classifier (no matter which) on a given data (you can use any 2-class dataset).

The dataset is stored in the object breast. The classifier is another object, called wc. You can inspect an object with the function dir(). E.g. you can type dir(breast).

The classifier is trained using its method fit(). Then you can get the output of the predictor. It is stored in the numpy array pred. In this classifier (Linear Discriminant Analysis) you can also retrieve the decision function value for each sample, which we will call scores, and the probabilities associated to each sample. Take a look at the documentation on the Internet.

As in matlab, you can compute the errors for the two classes by means of the confusion matrix (method confusion_matrix()). It can be computed in number of samples (most commonly) or normalised.

The results so far correspond to a classifier that has a threshold of 0.0 (note the different w.r.t Matlab, where the default threshold was 0.5. The two types of errors can be computed for different values of this threshold, leading to the ROC curve. Scikit-learn computes it for us if we call metrics.roc_curve.

You are supposed to do (at least) the following:

0) Compute TP and FP rates and display the TP/FP curve and the values of TP and FP for all thresholds. Display the results corresponding to the 0.0 threshold as points. (this is already done in the provided script).

1) Repeat exactly the same as in the previous item but use instead FP/FN as in the slides. 

2) Repeat again the same but use Precision/Recall measures. The definitions of precision and recall are in the slides. Try to understand what they mean also.

3) From the errors computed by metrics.roc_curve (for each class), obtain the average accuracy for all threshold values and display the corresponding curve in a figure. Plot the accuracy of the 0.0 threshold classifier as a point. Look for the best possible value along the average accuracy curve and mark it as a different point.

WHAT TO UPLOAD:

Add the code corresponding to items 1-3 at the end of the script and rename it as 'exercise01.1_XXX' where XXX are your initials. Upload this single file. Be sure to include an appropriate amount of comments along your code.

Even if you have problems and you cannot complete some or all the steps, upload the file and explain the kind of problems you have had.

Spicy version
If you complete the standard version and decide that it is to mild for you, then you can change the linear classifier by a QuadraticDiscriminantAnalysis classifier. To have a meaningful view of the results take into account two things. First, the range of the threshold can be very different to that in the linear case. Second, the roc curves provided by scikit-learn are simplified versions, in which many points have been dropped. Take a look to the optional parameter drop_intermediate of the method roc_curve().
Discuss, using comments, the possible differences between bot classifiers. In particular, compare the ROC curves of both classifiers and justify whether you would prefer any of the two classifiers.